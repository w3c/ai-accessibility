<!DOCTYPE html><html lang="en"><head>
<meta charset="utf-8">
<meta name="generator" content="ReSpec 35.4.1">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<style>
.issue-label{text-transform:initial}
.warning>p:first-child{margin-top:0}
.warning{padding:.5em;border-left-width:.5em;border-left-style:solid}
span.warning{padding:.1em .5em .15em}
.issue.closed span.issue-number{text-decoration:line-through}
.issue.closed span.issue-number::after{content:" (Closed)";font-size:smaller}
.warning{border-color:#f11;border-color:var(--warning-border,#f11);border-width:.2em;border-style:solid;background:#fbe9e9;background:var(--warning-bg,#fbe9e9);color:#000;color:var(--text,#000)}
.warning-title:before{content:"⚠";font-size:1.3em;float:left;padding-right:.3em;margin-top:-.3em}
li.task-list-item{list-style:none}
input.task-list-item-checkbox{margin:0 .35em .25em -1.6em;vertical-align:middle}
.issue a.respec-gh-label{padding:5px;margin:0 2px 0 2px;font-size:10px;text-transform:none;text-decoration:none;font-weight:700;border-radius:4px;position:relative;bottom:2px;border:none;display:inline-block}
</style>
<style>
dfn{cursor:pointer}
.dfn-panel{position:absolute;z-index:35;min-width:300px;max-width:500px;padding:.5em .75em;margin-top:.6em;font-family:"Helvetica Neue",sans-serif;font-size:small;background:#fff;background:var(--indextable-hover-bg,#fff);color:#000;color:var(--text,#000);box-shadow:0 1em 3em -.4em rgba(0,0,0,.3),0 0 1px 1px rgba(0,0,0,.05);box-shadow:0 1em 3em -.4em var(--tocsidebar-shadow,rgba(0,0,0,.3)),0 0 1px 1px var(--tocsidebar-shadow,rgba(0,0,0,.05));border-radius:2px}
.dfn-panel:not(.docked)>.caret{position:absolute;top:-9px}
.dfn-panel:not(.docked)>.caret::after,.dfn-panel:not(.docked)>.caret::before{content:"";position:absolute;border:10px solid transparent;border-top:0;border-bottom:10px solid #fff;border-bottom-color:var(--indextable-hover-bg,#fff);top:0}
.dfn-panel:not(.docked)>.caret::before{border-bottom:9px solid #a2a9b1;border-bottom-color:var(--indextable-hover-bg,#a2a9b1)}
.dfn-panel *{margin:0}
.dfn-panel b{display:block;color:#000;color:var(--text,#000);margin-top:.25em}
.dfn-panel ul a[href]{color:#333;color:var(--text,#333)}
.dfn-panel>div{display:flex}
.dfn-panel a.self-link{font-weight:700;margin-right:auto}
.dfn-panel .marker{padding:.1em;margin-left:.5em;border-radius:.2em;text-align:center;white-space:nowrap;font-size:90%;color:#040b1c}
.dfn-panel .marker.dfn-exported{background:#d1edfd;box-shadow:0 0 0 .125em #1ca5f940}
.dfn-panel .marker.idl-block{background:#8ccbf2;box-shadow:0 0 0 .125em #0670b161}
.dfn-panel a:not(:hover){text-decoration:none!important;border-bottom:none!important}
.dfn-panel a[href]:hover{border-bottom-width:1px}
.dfn-panel ul{padding:0}
.dfn-panel li{margin-left:1em}
.dfn-panel.docked{position:fixed;left:.5em;top:unset;bottom:2em;margin:0 auto;max-width:calc(100vw - .75em * 2 - .5em - .2em * 2);max-height:30vh;overflow:auto}
</style>
  
  
<title>Accessibility of machine learning and generative AI</title>
  
  
  
  

<style id="respec-mainstyle">
@keyframes pop{
0%{transform:scale(1,1)}
25%{transform:scale(1.25,1.25);opacity:.75}
100%{transform:scale(1,1)}
}
a.internalDFN{color:inherit;border-bottom:1px solid #99c;text-decoration:none}
a.externalDFN{color:inherit;border-bottom:1px dotted #ccc;text-decoration:none}
a.bibref{text-decoration:none}
.respec-offending-element:target{animation:pop .25s ease-in-out 0s 1}
.respec-offending-element,a[href].respec-offending-element{text-decoration:red wavy underline}
@supports not (text-decoration:red wavy underline){
.respec-offending-element:not(pre){display:inline-block}
.respec-offending-element{background:url(data:image/gif;base64,R0lGODdhBAADAPEAANv///8AAP///wAAACwAAAAABAADAEACBZQjmIAFADs=) bottom repeat-x}
}
#references :target{background:#eaf3ff;animation:pop .4s ease-in-out 0s 1}
cite .bibref{font-style:italic}
a[href].orcid{padding-left:4px;padding-right:4px}
a[href].orcid>svg{margin-bottom:-2px}
ol.tof,ul.tof{list-style:none outside none}
.caption{margin-top:.5em;font-style:italic}
#issue-summary>ul{column-count:2}
#issue-summary li{list-style:none;display:inline-block}
details.respec-tests-details{margin-left:1em;display:inline-block;vertical-align:top}
details.respec-tests-details>*{padding-right:2em}
details.respec-tests-details[open]{z-index:999999;position:absolute;border:thin solid #cad3e2;border-radius:.3em;background-color:#fff;padding-bottom:.5em}
details.respec-tests-details[open]>summary{border-bottom:thin solid #cad3e2;padding-left:1em;margin-bottom:1em;line-height:2em}
details.respec-tests-details>ul{width:100%;margin-top:-.3em}
details.respec-tests-details>li{padding-left:1em}
.self-link:hover{opacity:1;text-decoration:none;background-color:transparent}
aside.example .marker>a.self-link{color:inherit}
.header-wrapper{display:flex;align-items:baseline}
:is(h2,h3,h4,h5,h6):not(#toc>h2,#abstract>h2,#sotd>h2,.head>h2){position:relative;left:-.5em}
:is(h2,h3,h4,h5,h6):not(#toch2)+a.self-link{color:inherit;order:-1;position:relative;left:-1.1em;font-size:1rem;opacity:.5}
:is(h2,h3,h4,h5,h6)+a.self-link::before{content:"§";text-decoration:none;color:var(--heading-text)}
:is(h2,h3)+a.self-link{top:-.2em}
:is(h4,h5,h6)+a.self-link::before{color:#000}
@media (max-width:767px){
dd{margin-left:0}
}
@media print{
.removeOnSave{display:none}
}
</style>
<meta name="color-scheme" content="light">
<meta name="description" content="Recent advances in machine learning and generative artificial intelligence (AI) have expanded the range of problems for which effective computational solutions are feasible. Examples of such problems include improving the accuracy of speech recognition, image recognition, performing programming tasks, question answering, and natural language interaction. Machine learning technology also has unique and significant limitations. This document examines the consequences of these developments for the accessibility of the Web to people with disabilities, encompassing issues relevant to content authors, users, and accessibility evaluators. In doing so, it both addresses the potential benefits and clarifies issues that should be considered in the further evolution of Web standards and applications.">
<style>
var:hover{text-decoration:underline;cursor:pointer}
var.respec-hl{color:var(--color,#000);background-color:var(--bg-color);box-shadow:0 0 0 2px var(--bg-color)}
@media (prefers-color-scheme:dark){
var.respec-hl{filter:saturate(.9) brightness(.9)}
}
var.respec-hl-c1{--bg-color:#f4d200}
var.respec-hl-c2{--bg-color:#ff87a2}
var.respec-hl-c3{--bg-color:#96e885}
var.respec-hl-c4{--bg-color:#3eeed2}
var.respec-hl-c5{--bg-color:#eacfb6}
var.respec-hl-c6{--bg-color:#82ddff}
var.respec-hl-c7{--bg-color:#ffbcf2}
@media print{
var.respec-hl{background:0 0;color:#000;box-shadow:unset}
}
</style>
<style>
var{position:relative;cursor:pointer}
var[data-type]::after,var[data-type]::before{position:absolute;left:50%;top:-6px;opacity:0;transition:opacity .4s;pointer-events:none}
var[data-type]::before{content:"";transform:translateX(-50%);border-width:4px 6px 0 6px;border-style:solid;border-color:transparent;border-top-color:#222}
var[data-type]::after{content:attr(data-type);transform:translateX(-50%) translateY(-100%);background:#222;text-align:center;font-family:"Dank Mono","Fira Code",monospace;font-style:normal;padding:6px;border-radius:3px;color:#daca88;text-indent:0;font-weight:400}
var[data-type]:hover::after,var[data-type]:hover::before{opacity:1}
</style>
<script id="initialUserConfig" type="application/json">{
  "trace": true,
  "useExperimentalStyles": true,
  "doRDFa": "1.1",
  "includePermalinks": true,
  "permalinkEdge": true,
  "permalinkHide": false,
  "noRecTrack": true,
  "tocIntroductory": true,
  "lint": {
    "no-unused-dfns": false
  },
  "specStatus": "ED",
  "diffTool": "http://www.aptest.com/standards/htmldiff/htmldiff.pl",
  "shortName": "ai-accessibility",
  "copyrightStart": "2024",
  "license": "w3c-software-doc",
  "editors": [
    {
      "name": "Scott Hollier",
      "mailto": "scott.hollier@accessibility.org.au",
      "company": "Centre for Accessibility Australia",
      "companyURI": "https://www.accessibility.org.au/",
      "w3cid": 43274,
      "url": "mailto:scott.hollier@accessibility.org.au"
    },
    {
      "name": "Jason White",
      "mailto": "jason@jasonjgw.net",
      "w3cid": 74028,
      "url": "mailto:jason@jasonjgw.net"
    },
    {
      "name": "Janina Sajka",
      "url": "http://rednote.net/",
      "w3cid": 33688
    },
    {
      "name": "Joshue O'Connor",
      "mailto": "josh@interaccess.ie",
      "w3cid": 41218,
      "url": "mailto:josh@interaccess.ie"
    }
  ],
  "group": "apa",
  "github": "w3c/ai-accessibility",
  "maxTocLevel": 4,
  "preProcess": [
    null
  ],
  "postProcess": [
    null
  ],
  "publishISODate": "2025-06-24T00:00:00.000Z",
  "generatedSubtitle": "W3C Editor's Draft 24 June 2025"
}</script>
<link rel="stylesheet" href="https://www.w3.org/StyleSheets/TR/2021/W3C-ED"></head>

<body class="h-entry informative"><div class="head">
    <p class="logos"><a class="logo" href="https://www.w3.org/"><img crossorigin="" alt="W3C" height="48" src="https://www.w3.org/StyleSheets/TR/2021/logos/W3C" width="72">
  </a></p>
    <h1 id="title" class="title">Accessibility of machine learning and generative AI</h1> 
    <p id="w3c-state"><a href="https://www.w3.org/standards/types#ED">W3C Editor's Draft</a> <time class="dt-published" datetime="2025-06-24">24 June 2025</time></p>
    <details open="">
      <summary>More details about this document</summary>
      <dl>
        <dt>This version:</dt><dd>
                <a class="u-url" href="https://w3c.github.io/ai-accessibility/">https://w3c.github.io/ai-accessibility/</a>
              </dd>
        <dt>Latest published version:</dt><dd>
                <a href="https://www.w3.org/TR/ai-accessibility/">https://www.w3.org/TR/ai-accessibility/</a>
              </dd>
        <dt>Latest editor's draft:</dt><dd><a href="https://w3c.github.io/ai-accessibility/">https://w3c.github.io/ai-accessibility/</a></dd>
        <dt>History:</dt><dd>
                    <a href="https://github.com/w3c/ai-accessibility/commits/">Commit history</a>
                  </dd>
        
        
        
        
        
        <dt>Editors:</dt><dd class="editor p-author h-card vcard" data-editor-id="43274">
    <a class="ed_mailto u-email email p-name" href="mailto:scott.hollier@accessibility.org.au">Scott Hollier</a> (<span class="p-org org h-org">Centre for Accessibility Australia</span>)
  </dd><dd class="editor p-author h-card vcard" data-editor-id="74028">
    <a class="ed_mailto u-email email p-name" href="mailto:jason@jasonjgw.net">Jason White</a>
  </dd><dd class="editor p-author h-card vcard" data-editor-id="33688">
    <a class="u-url url p-name fn" href="http://rednote.net/">Janina Sajka</a>
  </dd><dd class="editor p-author h-card vcard" data-editor-id="41218">
    <a class="ed_mailto u-email email p-name" href="mailto:josh@interaccess.ie">Joshue O'Connor</a>
  </dd>
        
        
        <dt>Feedback:</dt><dd>
        <a href="https://github.com/w3c/ai-accessibility/">GitHub w3c/ai-accessibility</a>
        (<a href="https://github.com/w3c/ai-accessibility/pulls/">pull requests</a>,
        <a href="https://github.com/w3c/ai-accessibility/issues/new/choose">new issue</a>,
        <a href="https://github.com/w3c/ai-accessibility/issues/">open issues</a>)
      </dd>
        
        
      </dl>
    </details>
    
    
    <p class="copyright">
    <a href="https://www.w3.org/policies/#copyright">Copyright</a>
    ©
    2024-2025
    
    <a href="https://www.w3.org/">World Wide Web Consortium</a>.
    <abbr title="World Wide Web Consortium">W3C</abbr><sup>®</sup>
    <a href="https://www.w3.org/policies/#Legal_Disclaimer">liability</a>,
    <a href="https://www.w3.org/policies/#W3C_Trademarks">trademark</a> and
    <a rel="license" href="https://www.w3.org/copyright/software-license-2023/" title="W3C Software and Document Notice and License">permissive document license</a> rules apply.
  </p>
    <hr title="Separator for header">
  </div>
   <section id="abstract" class="introductory"><h2>Abstract</h2>
    <p>Recent advances in machine learning and generative artificial intelligence (<abbr>AI</abbr>) have expanded the range of problems for which effective computational solutions are feasible. Examples of such problems include improving the accuracy of speech recognition, image recognition, performing programming tasks, question answering, and natural language interaction. Machine learning technology also has unique and significant limitations. This document examines the consequences of these developments for the accessibility of the Web to people with disabilities, encompassing issues relevant to content authors, users, and accessibility evaluators. In doing so, it both addresses the potential benefits and clarifies issues that should be considered in the further evolution of Web standards and applications.</p>
    <p>Fundamental concepts of machine learning and generative AI are first introduced. The discussion then centers on a series of cases illustrative of accessibility related applications transformed by this technology.</p>
  </section>
  <section id="sotd" class="introductory"><h2>Status of This Document</h2><p><em>This section describes the status of this
      document at the time of its publication. A list of current <abbr title="World Wide Web Consortium">W3C</abbr>
      publications and the latest revision of this technical report can be found
      in the
      <a href="https://www.w3.org/TR/"><abbr title="World Wide Web Consortium">W3C</abbr> standards and drafts index</a> at
      https://www.w3.org/TR/.</em></p>
    <p>This is a draft collection of relevant information related to cross-disability accessibility guidance of how developments in machine learning and generative Artificial Intelligence (AI) clearly bears an impact on web accessibility standards and processes. Given the rapid changes in the consumption and development of AI design, this is intended to be a starting point to group the accessibility implications of machine learning and generative AI technologies.</p>
    <div class="note" id="tbd"><div role="heading" class="ednote-title marker" id="h-ednote" aria-level="3"><span>Editor's note</span></div><aside class="">
	    <p>This is an early draft of the document, circulated for initial public review. Future revisions are expected to have a different structure, and to address topic not treated in the current draft. These additional topics may include, but are not limited to, the following. Comments on scope and structure are welcome. See also section <a href="#scope" class="sec-ref"><bdi class="secno">2. </bdi>Purpose and Scope of this Document</a></p>
	    <ul>
		    <li>Accessibility issues raised by the use of machine learning and generative AI in Web-based applications, including its interactive role in contributing to the user interface.</li>
		    <li>The different considerations applicable to the application of machine learning in the authoring or content development environment, by contrast with the user's environment.</li>
        <li>Further discussion of the role of machine learning-based AI in evaluating the accessibility of Web content.</li>
		    <li>The use of generative AI in software development, and in particular for writing or enhancing user interface code.</li>
        <li>Clarification of the ways in which machine learning and generative AI affect computational problems relevant to accessibility, both positively in offering new functionality and opportunities for personalized interfaces, and negatively in creating unique risks.</li>
        <li>Achieving appropriate combinations of AI and human expertise in meeting challenges of accessibility.</li>
        <li>Approaches to evaluating and refining machine learning systems during their development that take into account accessibility-related requirements.</li>
	    </ul>
	    </aside></div>
  <p>
    This document was published by the <a href="https://www.w3.org/groups/wg/apa">Accessible Platform Architectures Working Group</a> as
    an Editor's Draft. 
  </p><p>Publication as an Editor's Draft does not
  imply endorsement by <abbr title="World Wide Web Consortium">W3C</abbr> and its Members. </p><p>
    This is a draft document and may be updated, replaced, or obsoleted by other
    documents at any time. It is inappropriate to cite this document as other
    than work in progress.
    
  </p><p>
    
        This document was produced by a group
        operating under the
        <a href="https://www.w3.org/policies/patent-policy/"><abbr title="World Wide Web Consortium">W3C</abbr> Patent
          Policy</a>.
      
    
                <abbr title="World Wide Web Consortium">W3C</abbr> maintains a
                <a rel="disclosure" href="https://www.w3.org/groups/wg/apa/ipr">public list of any patent disclosures</a>
          made in connection with the deliverables of
          the group; that page also includes
          instructions for disclosing a patent. An individual who has actual
          knowledge of a patent which the individual believes contains
          <a href="https://www.w3.org/policies/patent-policy/#def-essential">Essential Claim(s)</a>
          must disclose the information in accordance with
          <a href="https://www.w3.org/policies/patent-policy/#sec-Disclosure">section 6 of the <abbr title="World Wide Web Consortium">W3C</abbr> Patent Policy</a>.
        
  </p><p>
                      This document is governed by the
                      <a id="w3c_process_revision" href="https://www.w3.org/policies/process/20231103/">03 November 2023 <abbr title="World Wide Web Consortium">W3C</abbr> Process Document</a>.
                    </p></section><nav id="toc"><h2 class="introductory" id="table-of-contents">Table of Contents</h2><ol class="toc"><li class="tocline"><a class="tocxref" href="#abstract">Abstract</a></li><li class="tocline"><a class="tocxref" href="#sotd">Status of This Document</a></li><li class="tocline"><a class="tocxref" href="#introduction"><bdi class="secno">1. </bdi>Introduction</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#definitions"><bdi class="secno">1.1 </bdi>Definitions</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#artificial-intelligence"><bdi class="secno">1.1.1 </bdi>Artificial intelligence</a></li><li class="tocline"><a class="tocxref" href="#machine-learning"><bdi class="secno">1.1.2 </bdi>Machine learning</a></li><li class="tocline"><a class="tocxref" href="#generative-ai"><bdi class="secno">1.1.3 </bdi>Generative AI</a></li></ol></li><li class="tocline"><a class="tocxref" href="#accessibility-context"><bdi class="secno">1.2 </bdi>Accessibility context</a></li></ol></li><li class="tocline"><a class="tocxref" href="#scope"><bdi class="secno">2. </bdi>Purpose and Scope of this Document</a></li><li class="tocline"><a class="tocxref" href="#ai-authoring"><bdi class="secno">3. </bdi>AI and ML in authoring accessible content</a></li><li class="tocline"><a class="tocxref" href="#ai-accessibility-use-cases"><bdi class="secno">4. </bdi>AI and the User Perspective - accessibility use cases</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#relevance-of-current-standards-and-guidance"><bdi class="secno">4.1 </bdi>Relevance of current standards and guidance</a></li><li class="tocline"><a class="tocxref" href="#alternative-text-for-images"><bdi class="secno">4.2 </bdi>Alternative text for images</a></li><li class="tocline"><a class="tocxref" href="#automatic-speech-recognition-for-captioning"><bdi class="secno">4.3 </bdi>Automatic Speech Recognition for captioning</a></li><li class="tocline"><a class="tocxref" href="#plain-language"><bdi class="secno">4.4 </bdi>Plain language</a></li><li class="tocline"><a class="tocxref" href="#automated-language-detection"><bdi class="secno">4.5 </bdi>Automated Language detection</a></li><li class="tocline"><a class="tocxref" href="#colour-contrast"><bdi class="secno">4.6 </bdi>Colour contrast</a></li><li class="tocline"><a class="tocxref" href="#heading-structure"><bdi class="secno">4.7 </bdi>Heading structure</a></li><li class="tocline"><a class="tocxref" href="#adjustment-of-visual-spacing"><bdi class="secno">4.8 </bdi>Adjustment of visual spacing</a></li><li class="tocline"><a class="tocxref" href="#link-purpose"><bdi class="secno">4.9 </bdi> Link purpose</a></li><li class="tocline"><a class="tocxref" href="#sign-language"><bdi class="secno">4.10 </bdi>Sign language</a></li></ol></li><li class="tocline"><a class="tocxref" href="#evaluation-tools"><bdi class="secno">5. </bdi>AI for evaluation tools &amp; accessibility testing</a></li><li class="tocline"><a class="tocxref" href="#accessibility-user-interface"><bdi class="secno">6. </bdi>AI and user interface generation</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#accessibility-overlays"><bdi class="secno">6.1 </bdi>Accessibility Overlays</a></li></ol></li><li class="tocline"><a class="tocxref" href="#potential-harms-and-anti-patterns"><bdi class="secno">7. </bdi>Potential harms and anti-patterns in AI / ML</a></li><li class="tocline"><a class="tocxref" href="#reference-list"><bdi class="secno">8. </bdi>Reference List</a></li></ol></nav>
  <section id="introduction-0"><div class="header-wrapper"><h2 id="introduction"><bdi class="secno">1. </bdi>Introduction</h2><a class="self-link" href="#introduction" aria-label="Permalink for Section 1."></a></div>
    
    <section id="definitions-0"><div class="header-wrapper"><h3 id="definitions"><bdi class="secno">1.1 </bdi>Definitions</h3><a class="self-link" href="#definitions" aria-label="Permalink for Section 1.1"></a></div>
      
      <section id="artificial-intelligence-0"><div class="header-wrapper"><h4 id="artificial-intelligence"><bdi class="secno">1.1.1 </bdi>Artificial intelligence</h4><a class="self-link" href="#artificial-intelligence" aria-label="Permalink for Section 1.1.1"></a></div>
        
        <p>Artificial Intelligence refers to a machine or computer program's ability to think and learn without explicit instructions. The terminology “AI” in this context is generally thought to have been established by John McCarthy in 1955 (Xu et al., 2021). Although AI is used in a variety of disciplines, it is currently most relevant in machine learning and consumer applications known as generative AI.</p>
      </section>
      <section id="machine-learning-0"><div class="header-wrapper"><h4 id="machine-learning"><bdi class="secno">1.1.2 </bdi>Machine learning</h4><a class="self-link" href="#machine-learning" aria-label="Permalink for Section 1.1.2"></a></div>
        
        <p>Machine learning represents a field of study within the AI domain that has a focus towards statistical algorithm - capable of learning from data and performing tasks without specific instructions. This form of AI tends to focus on determinations and predictions.</p>
      </section>
      <section id="generative-ai-0"><div class="header-wrapper"><h4 id="generative-ai"><bdi class="secno">1.1.3 </bdi>Generative AI</h4><a class="self-link" href="#generative-ai" aria-label="Permalink for Section 1.1.3"></a></div>
        
        <p>While generative AI is generally classified as a subset of machine learning, its difference lies within its specific focus on creating new data based on specific human creative inputs such as text, images and audio (Zhihan Lv, 2023).</p>
      </section>
    </section>
    <section id="accessibility-context-0"><div class="header-wrapper"><h3 id="accessibility-context"><bdi class="secno">1.2 </bdi>Accessibility context</h3><a class="self-link" href="#accessibility-context" aria-label="Permalink for Section 1.2"></a></div>
      
      <p>The rapid increase in the use of machine learning and the specific focus on generative AI represents potential benefits and challenges in the context of Web accessibility provision. As online generative AI platforms such as ‘ChatGPT’ continue to offer consumers the unrestricted ability to create text and images, including video and audio from a variety of inputs, it is important to consider how accessible these outputs will be presented, and if machine learning algorithm may address broader accessibility issues in everyday tasks. For example, a web browser can use machine learning and generative AI to update content in real-time. This could be done through means such as the addition of alternative text to images which do not have one, and recognising text that should be a heading but is not marked correctly.</p>
      <p>These real-time changes would affect existing web standard such as the Web Content Accessibility Guidelines (WCAG), User Agent Accessibility Guidelines (UAAG) and the Authoring Tool Accessibility Guidelines (ATAG), assisting these standards in potentially addressing accessibility issues observed in various other accessibility related notes and resources. Furthermore, with the recent development by several manufacturers in launching computers and mobile devices with built-in Neural Processing Units (NPUs) to specifically support machine learning features on local devices, such as through the reduction of latency for live captioning. The potential for AI benefits within the web accessibility space could be profound.</p>
      <p>In addition, machine learning also raises the prospect for existing tools to be used in identifying and remediating accessibility issues. For instance, the proficiency of automated testing tools and accessibility overlays could be significantly increased to provide greater accessibility support and guidance to relevant developers and designers. The WCAG Success Criteria could also be improved in the sense of how much can be checked using AI, while increasing the applicability of automated remediation.</p>
      <p>However, the emerging nature of AI in its machine learning, and more specifically, its generative context, has made it difficult for users and developers alike to accurately perceive how effective automated accessibility tools are, and the degree of reliability they may offer in future directions. As such, this guidance is designed to provide some assistance in how machine learning is currently providing support, and its current level of effectiveness.</p>
    </section>
  </section>
  <section id="scope"><div class="header-wrapper"><h2 id="x2-purpose-and-scope-of-this-document"><bdi class="secno">2. </bdi>Purpose and Scope of this Document</h2><a class="self-link" href="#scope" aria-label="Permalink for Section 2."></a></div>
    
    <p>This document addresses issues of accessibility raised by machine learning and generative AI that lie within the following scope.</p>
    <ol>
      <li><p>The use of machine learning or generative AI to enhance the accessibility of Web content, including its application to</p>
        <ul>
          <li>code generation,</li>
          <li>web content creation and authoring tools,</li>
          <li>accessibility evaluation and content remediation, and</li>
          <li>the delivery of Web content to users (e.g., with automated accessibility enhancements).</li>
        </ul></li>
        <li><p>The application of machine learning-based AI by users themselves, including</p>
          <ul>
            <li>its use in assistive technologies,</li>
            <li>its application in accessibility-related features of user agents,</li>
            <li>its inclusion in the accessibility features of Web-based applications (e.g., in implementing speech recognition as part of an automated captioning feature in a meeting application), and</li>
            <li>the accessibility of Web-based applications that support the use of generative AI to create content, notably the problem of ensuring that the output of such applications satisfies accessibility requirements for authors and audiences with disabilities.</li>
          </ul></li>
    </ol>
    <p>In contributing to an understanding of these topics, this document</p>
    <ul>
      <li>Identifies accessibility issues to be considered in connection with the applications described above,</li>
      <li>identifies applicable <abbr title="World Wide Web Consortium">W3C</abbr> accessibility guidance that already exists, and</li>
      <li>characterizes potential approaches or solutions that may resolve the  accessibility issues identified.</li>
    </ul>
    <p>The principal audiences of this document are</p>
    <ul>
      <li>participants in relevant <abbr title="World Wide Web Consortium">W3C</abbr> Working Groups, Interest Groups, and Community Groups contributing to specifications, accessibility guidance, or Web technologies connected with machine learning or generative AI,</li>
      <li>Researchers or software developers engaged in the use of these technologies, and who wish to enhance their knowledge of accessibility issues prior to publication of any formal guidance by the <abbr title="World Wide Web Consortium">W3C</abbr> or inclusion of accessibility considerations in applicable <abbr title="World Wide Web Consortium">W3C</abbr> specifications, and</li>
      <li>Developers of applications employing machine learning, including generative AI, seeking to understand accessibility considerations prior to the development of any formal, <abbr title="World Wide Web Consortium">W3C</abbr> guidance.</li>
    </ul>
  </section>
  <section id="ai-and-ml-in-authoring-accessible-content"><div class="header-wrapper"><h2 id="ai-authoring"><bdi class="secno">3. </bdi>AI and ML in authoring accessible content</h2><a class="self-link" href="#ai-authoring" aria-label="Permalink for Section 3."></a></div>
    
    <p>@@ This section will discuss the nature of the role of AI and ML in assisting in the creation of accessible content. Some questions to consider are: What is needed in this space? How can we have confidence that AI/ML generated content is meeting real user needs? What does AI or ML do poorly? How can quality be determined? What guardrails are needed in order to ensure repair heuristics are of a high standard? </p>
  </section>

  <section id="ai-and-the-user-perspective-accessibility-use-cases"><div class="header-wrapper"><h2 id="ai-accessibility-use-cases"><bdi class="secno">4. </bdi>AI and the User Perspective - accessibility use cases</h2><a class="self-link" href="#ai-accessibility-use-cases" aria-label="Permalink for Section 4."></a></div>
    
    <p>@@ This section explores the current guidance and standards as well as what relevant standards need to be considered when incorporating AI or ML technologies into development pipelines for accessible content creation.</p>
    <section id="relevance-of-current-standards-and-guidance-0"><div class="header-wrapper"><h3 id="relevance-of-current-standards-and-guidance"><bdi class="secno">4.1 </bdi>Relevance of current standards and guidance</h3><a class="self-link" href="#relevance-of-current-standards-and-guidance" aria-label="Permalink for Section 4.1"></a></div>
      
      <p>The <abbr title="World Wide Web Consortium">W3C</abbr> Accessibility Initiative (WAI) consists of three guidelines capable of assisting in the creation of accessible content that may potentially be supported by AI features. These guidelines include standards relating to web content, user agents and authoring tools.</p>
      <p>The <a href="https://www.w3.org/TR/WCAG22/">Web Content Accessibility Guidelines (WCAG) 2.2</a> features several guidelines and success criteria (SC) that are potentially being addressed, such as SC 1.1.1 with the provision of automated alternative text, and SC 1.2.4 with the provision of time-based media through automated live captioning.</p>
      <p>In addition, the <a href="https://www.w3.org/TR/ATAG20/">User Agent Accessibility (UAAG) Guidelines 2.0</a> could suggest that user agents, like web browsers with generative AI, could make real-time adjustments during browsing sessions, such as fixing color contrast issues and improving poor heading structures through the interpretation of codes.</p>
      <p>Furthermore, the <a href="https://www.w3.org/TR/UAAG20/">Authoring Tool Accessibility Guidelines (ATAG) 2.0</a> could also offer support, particularly in Part B, in which the creation of accessible content is of particular importance. For example, authoring tools that have automatically generated alternative text could support the creation of accessible content.</p>
    </section>
    <section id="alternative-text-for-images-0"><div class="header-wrapper"><h3 id="alternative-text-for-images"><bdi class="secno">4.2 </bdi>Alternative text for images</h3><a class="self-link" href="#alternative-text-for-images" aria-label="Permalink for Section 4.2"></a></div>
      
      <p>There currently exists a number of machine learning-based tools that have been integrated into popular social media platforms, alongside authoring tools, that are equipped to create an automated alternative text description based on machine learning algorithms that scan and determine the contents of visual materials, such as an image. Until recently, this automated process was considered to hold high inaccuracy to the point where its utility was questioned (Leotta et al., 2022). Recent developments have improved automated alternative text accuracy, but criticism persists due to limitations in providing detail and recognising the importance of relevant data.</p>
      <figure id="fig-a-coloured-bar-graph-representing-the-favourite-colour-of-children-inspired-by-an-example-from-twinkl-n-d"><img src="bar-graph.png" alt="A graph with different colored bars Description automatically generated">
        <figcaption><a class="self-link" href="#fig-a-coloured-bar-graph-representing-the-favourite-colour-of-children-inspired-by-an-example-from-twinkl-n-d">Figure <bdi class="figno">1</bdi></a> <span class="fig-title">A coloured bar graph representing the favourite colour of children (inspired by an example from Twinkl, n.d.)</span></figcaption>
      </figure>
      <p>A good example can be seen in a popular image used to illustrate data (Twinkl, n.d.). The image features a classic bar graph of responses from children clarifying their favourite colour, in which yellow has been found the achieve the highest result with 9 responses. While an appropriate alternative text for the image should endeavour to capture the significant points of the graph with detail, such as its drawn intention - the information organising its X and Y axis, as well as the resulting data, the automated alternative text simply describes this image as “a graph with different coloured bars”. While technically accurate, this information lacks depth to convey important technical details from the graph.</p>
      <figure id="fig-an-image-provided-by-the-james-webb-space-telescope"><img src="image2.jpeg" alt="A nebula in space with stars Description automatically generated">
        <figcaption><a class="self-link" href="#fig-an-image-provided-by-the-james-webb-space-telescope">Figure <bdi class="figno">2</bdi></a> <span class="fig-title">An image provided by the James Webb Space Telescope</span></figcaption>
      </figure>
      <p>A second example is shown through an image from the James Webb Space Telescope. As all images publicly released include automated alternative text, the alternative text for Figure 2 was compared to that of a manually created alternative text. The former reads the description, “The image is divided horizontally by an undulating line between a cloudscape forming a nebula along the bottom portion and a comparatively clear upper portion”, while the latter states: “Speckled across both portions is a starfield, showing innumerable stars of many sizes. The smallest of these are small, distant, and faint points of light. The largest of these appear larger, closer, brighter, and more fully resolved with 8-point diffraction spikes. The upper portion of the image is bluish and has wispy translucent cloudlike streaks rising from the nebula below.”</p>
      <p>Upon observation, the automated alternative text presents a simplified iteration of the image, using the brief narration, “a nebula in space with stars”. As such, once again, this comparison supports that, while automated alternative text provided by machine learning is representative of the image being studied and could assist in delivering a basic and minimised understanding of an image, it does not have the ability to incorporate the orientation of detail required to capture the essence of the image.</p>
      <p>Although machine learning techniques embedded in authoring tools and other platforms may provide some information, generative AI platforms that are able to create images, videos and other visual media content based on text input tend not to provide automated alternative text. Hence, this would make it difficult for people who are blind or have low vision to attain a meaningful interpretation of these AI-generated outputs.</p>
    </section>
    <section id="automatic-speech-recognition-for-captioning-0"><div class="header-wrapper"><h3 id="automatic-speech-recognition-for-captioning"><bdi class="secno">4.3 </bdi>Automatic Speech Recognition for captioning</h3><a class="self-link" href="#automatic-speech-recognition-for-captioning" aria-label="Permalink for Section 4.3"></a></div>
      
      <p>A common alternative accessibility support is the provision of live captioning through the features of Automated Speech Recognition (ASR) processes, whereby generative AI is employed to sample speech and convert them into captions as the same language, or subtitles in a different language.</p>
      <p>Until recently, the accuracy and validity of ASR techniques in the same language were considered as ineffective practices as the translation quality was poor due to an extra machine learning step that attempted to convert ASR outputs further. Currently however, the provision of captions has become increasingly reliable, with an approximate success rate of 85%. Furthermore, its ability to translate in real time has improved substantially (Millett, 2021).</p>
      <p>While ASR captions may provide merits when serving the role of a complementary tool alongside curated content, it is still generally perceived by the Deaf community as lacking in accuracy, thereby preventing ASR from being considered as a truly beneficial feature. Other issues associated with ASR may include delays in processing time, as most contemporary solutions require devices to be connected for the generative AI features to occur online, the lack of grammar and punctuation, the lack of block captioning associated with pre-recorded materials, and the necessity for good quality audio in a quiet environment in order for ASR to optimise its output.</p>
      <p>However, that is not to discredit the fact that some of these issues are beginning to be corrected. With the introduction of NPUs into consumer devices, ASR captions can be rendered on devices rather than online. Early testing suggests that this significantly improves the speed of captions being presented, as well as provides enhanced auto-correction features in an instance where ASR misunderstands a word or phrase.</p>
      <p>While these advancements do not resolve all issues of ASR, and the notion remains that this process is still not adequately accessible as a standalone feature, they demonstrate that current generative AI processes are capable of potentially contributing to accessibility improvements.</p>
      <p>ASR technologies may also be applied to audio-only material in which pre-recorded content could be provided to a generative AI process to output a transcript. While the removal of real-time ASR may increase reliability to a point where some specialist writing tools could be applicable to utilise this function, issues of accuracy, spelling, grammar, punctuation and errors persist.</p>
    </section>
    <section id="plain-language-0"><div class="header-wrapper"><h3 id="plain-language"><bdi class="secno">4.4 </bdi>Plain language</h3><a class="self-link" href="#plain-language" aria-label="Permalink for Section 4.4"></a></div>
      
      <p>Current demonstrations of generative AI often employ examples of language being translated or simplified to showcase the potential of these mechanisms. While the ability for popular AI platforms to convert language based on specific word count, rhyming pattern and subject matter are often viewed as successful outcomes, converting complex language content to the level of lower secondary reading abilities often require human intervention.</p>
      <p>Key concepts including the need for common words, the definition of words, and the removal of double negatives are exemplary demonstrations of how generative AI may achieve some positive effects. However, other plain language concepts such as the conversion of text into literal language, understanding different grammar tenses, and addressing text with nested clauses highlight some current limitations of AI. For example, a translation of the popular poem, “Mary Had a Little Lamb”, into a non-English language, and then back to English observes the error of “it’s fleece was white as snow” being converted to “it snowed sheep hair”. While the other lines in the poem were largely accurately translated, the issue of literal language and the shortcoming of generative AI in understanding regional contexts and language structures remains.</p>
    </section>
    <section id="automated-language-detection-0"><div class="header-wrapper"><h3 id="automated-language-detection"><bdi class="secno">4.5 </bdi>Automated Language detection</h3><a class="self-link" href="#automated-language-detection" aria-label="Permalink for Section 4.5"></a></div>
      
      <p>Within the WCAG 2.2 standard, Guideline 3.1 explains the necessity to globally define language on a page, as well as when there is a change of language in parts. This would then allow assistive technologies to understand the language change and adjust its language selection accordingly. A potential benefit to machine learning could be the improved ability in identifying the type of language used. This would then enable assistive technologies such as screen readers to select that language if supported.</p>
      <p>Although there are few examples in a web context where the language of content is defined by machine learning processes, rather than coded directly, the ability for assistive technologies to immediately comprehend the language being presented could provide a considerable benefit.</p>
    </section>
    <section id="colour-contrast-0"><div class="header-wrapper"><h3 id="colour-contrast"><bdi class="secno">4.6 </bdi>Colour contrast</h3><a class="self-link" href="#colour-contrast" aria-label="Permalink for Section 4.6"></a></div>
      
      <p>Another area where machine learning could identify an issue lies in the remediation of colour contrast issues as they are recognised. Automated testing tools at present are capable of detecting some colour contrast issues (Almeida and Duarte, 2020), hence, the possibility of real-time remediation could be likely in the case that a detected text colour contrast is below the 4.5:1 colour contrast ratio for foreground, background and text colour, or the 3:1 colour contrast ratio for user interface elements. With generative AI processes, these elements could be made more contrasting through colour adjustments, while largely preserving the colours intended by the original author.</p>
    </section>
    <section id="heading-structure-0"><div class="header-wrapper"><h3 id="heading-structure"><bdi class="secno">4.7 </bdi>Heading structure</h3><a class="self-link" href="#heading-structure" aria-label="Permalink for Section 4.7"></a></div>
      
      <p>Currently, the use of elements such as bold text to look like a heading without the provision of a programmatically determined heading structure is a significant accessibility issue that remains in web content. With a generative AI feature, web pages or app screens can visually identify headings and their nested content, utilising current technologies. While there is presently no awareness of its potential implementation, the remediation of heading structure represents a significant opportunity to provide improvements in readability and navigation should generative AI be capable of effectively addressing this issue.</p>
    </section>
    <section id="adjustment-of-visual-spacing-0"><div class="header-wrapper"><h3 id="adjustment-of-visual-spacing"><bdi class="secno">4.8 </bdi>Adjustment of visual spacing</h3><a class="self-link" href="#adjustment-of-visual-spacing" aria-label="Permalink for Section 4.8"></a></div>
      
      <p>At present, some web browsers offer the proficiency to structurally reorder web content to optimise the aspect of readability. As enhancements in machine learning continues, it is likely that such features will continue to improve and confront accessibility concerns relating to text, word, and line spacing for the purpose of better supporting people with a cognitive and print disability.</p>
    </section>
    <section id="link-purpose-0"><div class="header-wrapper"><h3 id="link-purpose"><bdi class="secno">4.9 </bdi> Link purpose</h3><a class="self-link" href="#link-purpose" aria-label="Permalink for Section 4.9"></a></div>
      
      <p>Presently, a widespread issue existing within online channels may be attributed to the use of non-descriptive links such as “click here” or “read more”, as identified in WCAG 2.2 SC 2.4.4 Link Purpose. While it is currently necessary to create links with a descriptive text to remediate the issue, generative AI represents an opportunity for issues to be addressed in real-time. This could be accomplished through the employment of AI following a non-descriptive link to its source, and distinguishing its content before resolving the link for users in a manner that is more indicative of what the link represents.</p>
    </section>
    <section id="sign-language-0"><div class="header-wrapper"><h3 id="sign-language"><bdi class="secno">4.10 </bdi>Sign language</h3><a class="self-link" href="#sign-language" aria-label="Permalink for Section 4.10"></a></div>
      
      <p>The utility of sign language in relation to WCAG presently stands as a Level AAA success criterion that is not as widely implemented within policy-related legislative frameworks, with compliancy up to Level AA appearing to be the most adopted. Thus, support for sign language is limited within time-based media such as online videos.</p>
      <p>However, thanks to generative AI, it is now feasible to provide language translation services from text or symbol-based languages to sign language. Some websites and movie apps already offer a limited version of this capability. On the other hand, while this observation shows promise for the future use of sign language, the effectiveness of generative AI in translating sign language, coupled with the diverse localised variations in sign language across countries, poses challenges for providing a fully effective automated solution at this time.</p>
    </section>
  </section>
  <section id="ai-for-evaluation-tools-accessibility-testing"><div class="header-wrapper"><h2 id="evaluation-tools"><bdi class="secno">5. </bdi>AI for evaluation tools &amp; accessibility testing</h2><a class="self-link" href="#evaluation-tools" aria-label="Permalink for Section 5."></a></div>
    
    <p>At present, there are several automated testing tools available based on coding assessments within websites, apps and documents. Such tools are often employed to identify issues of non-compliance with the WCAG standard, additionally providing subsequent guidance in remediation. Some of these tools are free of charge but limited in functionality, while others provide enterprise-level remediation guidance, and is capable of monitoring web content in real time.</p>
    <p>Although these tools are generally considered a helpful companion for remediation, they currently possess flaws; some notable issues include acquiring different results between the use of different tools (Ismailova &amp; Inal, 2022), difficulty in determining if the tool has identified a specific issue, or simply noting that the issue requires review. These issues follow research that has constantly indicated automated tools bear the restricted capacity of executing low-level coverage in checking and recommending remediations, with the remaining requiring some form of intervention (Vigo et al., 2013).</p>
    <p>While automated testing tools have been largely based on scripting language such as JavaScript to manually review and report on code, deep machine learning is likely to improve these tools to a considerable degree going forward, allowing the application of generative AI processes to more clearly identified issues. For instance, most tools may accurately determine if alternative text is available for images but cannot determine the effectiveness of present alternative text. With the inclusion of generative AI, improvements are likely to be offered in what automated tools can evaluate, such as the quality of captions, descriptive links and correcting other issues mentioned previously such as the use of language and headings. Although there is currently little evidence of generative AI featuring in such tools, it is very much possible that testing and evaluation of web content will improve along with the rest of the rapidly evolving generative AI content.</p>
  </section>
  <section id="ai-and-user-interface-generation"><div class="header-wrapper"><h2 id="accessibility-user-interface"><bdi class="secno">6. </bdi>AI and user interface generation</h2><a class="self-link" href="#accessibility-user-interface" aria-label="Permalink for Section 6."></a></div>
    
    <p>@@This section will discuss how AI can be used to create and/or modify the user interface. Some core things to consider: What need is being met when we ask AI to modify or change a UI? What does an MVP AI generated UI look like?. How will the quality of generated user interfaces be determined? Are there potential harms and anti-patterns that need to be considered?</p>
    <section id="accessibility-overlays-0"><div class="header-wrapper"><h3 id="accessibility-overlays"><bdi class="secno">6.1 </bdi>Accessibility Overlays</h3><a class="self-link" href="#accessibility-overlays" aria-label="Permalink for Section 6.1"></a></div>
    <p>The rapid increase of accessibility overlays on websites has been viewed as rather controversial by people with disability. While these tools could be useful for individuals unfamiliar with assistive technologies that are built into computing and mobile devices, critics of overlays point to the tools being marketed as an accessibility solution, thus causing the code to interrupt the use of more developed assistive technologies such as screen readers (Morris, 2022). Furthermore, these overlay features carry the tendency to be limited in functionality as compared to tools installed in an operating system.</p>
    <p>However, the promise of generative AI may be able to address the criticism that such tools lack functionality. An accessibility overlay capable of utilising generative AI functionality may be able to provide increased real-time support in overcoming accessibility issues or improving its interpretation of content, such as for images, language and page structure. Although these tools are currently promoted as a collection of accessibility features somewhat independent from the content, the applicability of an overlay that contributes accessibility improvements is similar to the use of AI chatbots and other prompting mechanisms, thereby suggesting this may prove to be another area where generative AI could introduce improvements.</p>
  </section></section>
  <section id="potential-harms-and-anti-patterns-in-ai-ml"><div class="header-wrapper"><h2 id="potential-harms-and-anti-patterns"><bdi class="secno">7. </bdi>Potential harms and anti-patterns in AI / ML</h2><a class="self-link" href="#potential-harms-and-anti-patterns" aria-label="Permalink for Section 7."></a></div>
    
    <p>@@This section looks at some of the existential aspects of AI / ML. These are in the context of supporting the needs of people with disabilities successfully, and explores the role of AI/ML from the perspective of its principle etiology or reason for being and how that may impact the field of accessibility for better or for worse. </p> 
    <p>There are also some potential threats in terms of the deterioration of overall quality in the field, or moving towards an overreliance on tools that may be fundamentally flawed or biased.</p>
    <p>There are secondary issues or harms inherent in outsourcing human expertise where quality aspects of universal or inclusive design that are often from deep human practitioner may come in sharp contrast with brute force computational approaches to 'fixing the web' that may have a lighter architecture or be built on superficial or weaker knowledge.</p>
    <p>These AI / ML approaches may be then built on leaky abstractions and weaker understanding of both the technical requirements of best practices and the user needs they are trying to address.</p>
  </section>
  <section id="reference-list-0"><div class="header-wrapper"><h2 id="reference-list"><bdi class="secno">8. </bdi>Reference List</h2><a class="self-link" href="#reference-list" aria-label="Permalink for Section 8."></a></div>
    
    <p>Almeida, R., &amp; Duarte, C. M. (2020). Analysis of automated contrast checking tools.&nbsp;<em>Proceedings of the 17th International Web for All Conference</em>, 1–4. https://doi.org/10.1145/3371300.3383348</p>
    <p>Ismailova, R., &amp; Inal, Y. (2022). Comparison of Online Accessibility Evaluation Tools: An Analysis of Tool Effectiveness.&nbsp;<em>IEEE Access</em>,&nbsp;<em>10</em>, 58233–58239. https://doi.org/10.1109/access.2022.3179375</p>
    <p>Leotta, M., Mori, F., &amp; Ribaudo, M. (2022). Evaluating the effectiveness of automatic image captioning for web accessibility.&nbsp;<em>Universal Access in the Information Society</em>, 1–21. https://doi.org/10.1007/s10209-022-00906-7</p>
    <p>Millett, P. (2021).&nbsp;<em>Accuracy of Speech-to-Text Captioning for Students Who are Deaf or Hard of Hearing</em>&nbsp;(pp. 1–13). https://www.edaud.org/journal/2021/1-article-21.pdf</p>
    <p>Morris, A. (2022, July 13). For Blind Internet Users, the Fix Can Be Worse Than the Flaws.&nbsp;<em>The New York Times</em>. https://www.nytimes.com/2022/07/13/technology/ai-web-accessibility.html</p>
    <p>Twinkl. (n.d.).&nbsp;<em>What is Bar Chart?</em>&nbsp;[Image ]. Retrieved June 24, 2024, from https://www.twinkl.de/teaching-wiki/bar-chart</p>
    <p>Vigo, M., Brown, J., &amp; Conway, V. (2013). Benchmarking web accessibility evaluation tools.&nbsp;<em>Proceedings of the 10th International Cross-Disciplinary Conference on Web Accessibility - W4A ’13</em>, 1–10. https://doi.org/10.1145/2461121.2461124</p>
    <p>Xu, Y., Wang, Q., An, Z., Wang, F., Zhang, L., Wu, Y., Dong, F., Qiu, C.-W., Liu, X., Qiu, J., Hua, K., Su, W., Xu, H., Han, Y., Cao, X., Liu, E., Fu, C., Yin, Z., Liu, M., &amp; Roepman, R. (2021). Artificial Intelligence: a Powerful Paradigm for Scientific Research.&nbsp;<em>The Innovation</em>,&nbsp;<em>2</em>(4). Sciencedirect. https://doi.org/10.1016/j.xinn.2021.100179</p>
    <p>Zhihan Lv. (2023). Generative Artificial Intelligence in the Metaverse Era.&nbsp;<em>Cognitive Robotics</em>,&nbsp;<em>3</em>, 208–217. https://doi.org/10.1016/j.cogr.2023.06.001</p>
  </section>



<p role="navigation" id="back-to-top">
    <a href="#title"><abbr title="Back to Top">↑</abbr></a>
  </p><script id="respec-highlight-vars">(() => {
// @ts-check

if (document.respec) {
  document.respec.ready.then(setupVarHighlighter);
} else {
  setupVarHighlighter();
}

function setupVarHighlighter() {
  document
    .querySelectorAll("var")
    .forEach(varElem => varElem.addEventListener("click", highlightListener));
}

function highlightListener(ev) {
  ev.stopPropagation();
  const { target: varElem } = ev;
  const hightligtedElems = highlightVars(varElem);
  const resetListener = () => {
    const hlColor = getHighlightColor(varElem);
    hightligtedElems.forEach(el => removeHighlight(el, hlColor));
    [...HL_COLORS.keys()].forEach(key => HL_COLORS.set(key, true));
  };
  if (hightligtedElems.length) {
    document.body.addEventListener("click", resetListener, { once: true });
  }
}

// availability of highlight colors. colors from var.css
const HL_COLORS = new Map([
  ["respec-hl-c1", true],
  ["respec-hl-c2", true],
  ["respec-hl-c3", true],
  ["respec-hl-c4", true],
  ["respec-hl-c5", true],
  ["respec-hl-c6", true],
  ["respec-hl-c7", true],
]);

function getHighlightColor(target) {
  // return current colors if applicable
  const { value } = target.classList;
  const re = /respec-hl-\w+/;
  const activeClass = re.test(value) && value.match(re);
  if (activeClass) return activeClass[0];

  // first color preference
  if (HL_COLORS.get("respec-hl-c1") === true) return "respec-hl-c1";

  // otherwise get some other available color
  return [...HL_COLORS.keys()].find(c => HL_COLORS.get(c)) || "respec-hl-c1";
}

function highlightVars(varElem) {
  const textContent = norm(varElem.textContent);
  const parent = varElem.closest(".algorithm, section");
  const highlightColor = getHighlightColor(varElem);

  const varsToHighlight = [...parent.querySelectorAll("var")].filter(
    el =>
      norm(el.textContent) === textContent &&
      el.closest(".algorithm, section") === parent
  );

  // update availability of highlight color
  const colorStatus = varsToHighlight[0].classList.contains("respec-hl");
  HL_COLORS.set(highlightColor, colorStatus);

  // highlight vars
  if (colorStatus) {
    varsToHighlight.forEach(el => removeHighlight(el, highlightColor));
    return [];
  } else {
    varsToHighlight.forEach(el => addHighlight(el, highlightColor));
  }
  return varsToHighlight;
}

function removeHighlight(el, highlightColor) {
  el.classList.remove("respec-hl", highlightColor);
  // clean up empty class attributes so they don't come in export
  if (!el.classList.length) el.removeAttribute("class");
}

function addHighlight(elem, highlightColor) {
  elem.classList.add("respec-hl", highlightColor);
}

/**
 * Same as `norm` from src/core/utils, but our build process doesn't allow
 * imports in runtime scripts, so duplicated here.
 * @param {string} str
 */
function norm(str) {
  return str.trim().replace(/\s+/g, " ");
}
})()</script><script id="respec-dfn-panel">(() => {
// @ts-check
if (document.respec) {
  document.respec.ready.then(setupPanel);
} else {
  setupPanel();
}

function setupPanel() {
  const listener = panelListener();
  document.body.addEventListener("keydown", listener);
  document.body.addEventListener("click", listener);
}

function panelListener() {
  /** @type {HTMLElement} */
  let panel = null;
  return event => {
    const { target, type } = event;

    if (!(target instanceof HTMLElement)) return;

    // For keys, we only care about Enter key to activate the panel
    // otherwise it's activated via a click.
    if (type === "keydown" && event.key !== "Enter") return;

    const action = deriveAction(event);

    switch (action) {
      case "show": {
        hidePanel(panel);
        /** @type {HTMLElement} */
        const dfn = target.closest("dfn, .index-term");
        panel = document.getElementById(`dfn-panel-for-${dfn.id}`);
        const coords = deriveCoordinates(event);
        displayPanel(dfn, panel, coords);
        break;
      }
      case "dock": {
        panel.style.left = null;
        panel.style.top = null;
        panel.classList.add("docked");
        break;
      }
      case "hide": {
        hidePanel(panel);
        panel = null;
        break;
      }
    }
  };
}

/**
 * @param {MouseEvent|KeyboardEvent} event
 */
function deriveCoordinates(event) {
  const target = /** @type HTMLElement */ (event.target);

  // We prevent synthetic AT clicks from putting
  // the dialog in a weird place. The AT events sometimes
  // lack coordinates, so they have clientX/Y = 0
  const rect = target.getBoundingClientRect();
  if (
    event instanceof MouseEvent &&
    event.clientX >= rect.left &&
    event.clientY >= rect.top
  ) {
    // The event probably happened inside the bounding rect...
    return { x: event.clientX, y: event.clientY };
  }

  // Offset to the middle of the element
  const x = rect.x + rect.width / 2;
  // Placed at the bottom of the element
  const y = rect.y + rect.height;
  return { x, y };
}

/**
 * @param {Event} event
 */
function deriveAction(event) {
  const target = /** @type {HTMLElement} */ (event.target);
  const hitALink = !!target.closest("a");
  if (target.closest("dfn:not([data-cite]), .index-term")) {
    return hitALink ? "none" : "show";
  }
  if (target.closest(".dfn-panel")) {
    if (hitALink) {
      return target.classList.contains("self-link") ? "hide" : "dock";
    }
    const panel = target.closest(".dfn-panel");
    return panel.classList.contains("docked") ? "hide" : "none";
  }
  if (document.querySelector(".dfn-panel:not([hidden])")) {
    return "hide";
  }
  return "none";
}

/**
 * @param {HTMLElement} dfn
 * @param {HTMLElement} panel
 * @param {{ x: number, y: number }} clickPosition
 */
function displayPanel(dfn, panel, { x, y }) {
  panel.hidden = false;
  // distance (px) between edge of panel and the pointing triangle (caret)
  const MARGIN = 20;

  const dfnRects = dfn.getClientRects();
  // Find the `top` offset when the `dfn` can be spread across multiple lines
  let closestTop = 0;
  let minDiff = Infinity;
  for (const rect of dfnRects) {
    const { top, bottom } = rect;
    const diffFromClickY = Math.abs((top + bottom) / 2 - y);
    if (diffFromClickY < minDiff) {
      minDiff = diffFromClickY;
      closestTop = top;
    }
  }

  const top = window.scrollY + closestTop + dfnRects[0].height;
  const left = x - MARGIN;
  panel.style.left = `${left}px`;
  panel.style.top = `${top}px`;

  // Find if the panel is flowing out of the window
  const panelRect = panel.getBoundingClientRect();
  const SCREEN_WIDTH = Math.min(window.innerWidth, window.screen.width);
  if (panelRect.right > SCREEN_WIDTH) {
    const newLeft = Math.max(MARGIN, x + MARGIN - panelRect.width);
    const newCaretOffset = left - newLeft;
    panel.style.left = `${newLeft}px`;
    /** @type {HTMLElement} */
    const caret = panel.querySelector(".caret");
    caret.style.left = `${newCaretOffset}px`;
  }

  // As it's a dialog, we trap focus.
  // TODO: when <dialog> becomes a implemented, we should really
  // use that.
  trapFocus(panel, dfn);
}

/**
 * @param {HTMLElement} panel
 * @param {HTMLElement} dfn
 * @returns
 */
function trapFocus(panel, dfn) {
  /** @type NodeListOf<HTMLAnchorElement> elements */
  const anchors = panel.querySelectorAll("a[href]");
  // No need to trap focus
  if (!anchors.length) return;

  // Move focus to first anchor element
  const first = anchors.item(0);
  first.focus();

  const trapListener = createTrapListener(anchors, panel, dfn);
  panel.addEventListener("keydown", trapListener);

  // Hiding the panel releases the trap
  const mo = new MutationObserver(records => {
    const [record] = records;
    const target = /** @type HTMLElement */ (record.target);
    if (target.hidden) {
      panel.removeEventListener("keydown", trapListener);
      mo.disconnect();
    }
  });
  mo.observe(panel, { attributes: true, attributeFilter: ["hidden"] });
}

/**
 *
 * @param {NodeListOf<HTMLAnchorElement>} anchors
 * @param {HTMLElement} panel
 * @param {HTMLElement} dfn
 * @returns
 */
function createTrapListener(anchors, panel, dfn) {
  const lastIndex = anchors.length - 1;
  let currentIndex = 0;
  return event => {
    switch (event.key) {
      // Hitting "Tab" traps us in a nice loop around elements.
      case "Tab": {
        event.preventDefault();
        currentIndex += event.shiftKey ? -1 : +1;
        if (currentIndex < 0) {
          currentIndex = lastIndex;
        } else if (currentIndex > lastIndex) {
          currentIndex = 0;
        }
        anchors.item(currentIndex).focus();
        break;
      }

      // Hitting "Enter" on an anchor releases the trap.
      case "Enter":
        hidePanel(panel);
        break;

      // Hitting "Escape" returns focus to dfn.
      case "Escape":
        hidePanel(panel);
        dfn.focus();
        return;
    }
  };
}

/** @param {HTMLElement} panel */
function hidePanel(panel) {
  if (!panel) return;
  panel.hidden = true;
  panel.classList.remove("docked");
}
})()</script><script src="https://www.w3.org/scripts/TR/2021/fixup.js"></script></body></html>